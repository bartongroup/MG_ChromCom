---
title: "Chromosome compation - simple 3-state model"
author: "Marek Gierlinski"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    number_sections: true
---

Collaborators: Tomo Tanaka, John Eykelenboom.

[shiny app](https://shiny.compbio.dundee.ac.uk/marek_chromcom/param_tuner/)

```{r setup, include=FALSE}
library(knitr)
library(mylib)
library(ggplot2)
library(gridExtra)
library(latex2exp)
library(kableExtra)

source("../R/lib.R")
binDir <- "../RData"

opts_chunk$set(fig.path='../figure/mpd3-', 
               cache.path='../cache/mod3-', 
               fig.align='center',
               external=TRUE,
               echo=FALSE,
               warning=FALSE,
               message=FALSE,
               fig.pos='H',
               fig.width=4,
               fig.height=3
              )
smth <- 5
```

# Data

```{r read_experimental_data}
echr <- lapply(dataFile, experimentalData)
```

In our data we distinguish four states, marked by colour: blue, brown, pink, red. For the purpose of the model we merge blue and brown together into one state. Here is the result of the experiment from `r nrow(echr$scramble$cells)` cells.

```{r fig_cells, fig.width=5}
plotCells(echr$scramble)
```

The next figure shows the proportions of each colour as a function of time. The curves are smoothed with a running mean over the window of `r smth` time points.

```{r fig_timeline, fig.width=5}
plotTimelines(echr$scramble, smooth=TRUE, k=smth)
```


# Model

The model consists of three states and a set of rules.

## States

* blue/brown (B)
* pink (P)
* red (R)
 
## Rules

- Simulation is carried out at a discrete time step of 1 min
- There is a fixed time for nuclear envelope breakdown, $t_0 = 0$; $t_0$ can be changed if necessary
- Time $t_1$ is a random variable with exponential distribution with time scale $\tau_1$
- Time $\Delta t_2$ is a random variable with exponential distribution with time scale $\tau_2$
- Time $\Delta t_3$ is a random variable with exponential distribution with time scale $\tau_3$
- The cell is in state B before time $t_0-t_1$.
- B$\rightarrow$P occurs after $t_0-t_1$ with rate $k_1$
- P$\rightarrow$R occurs after $t_0-t_1 + \Delta t_2$ with rate $k_2$*
- P$\rightarrow$B occurs after $t_0-t_1 + \Delta t_3$ with rate $k_3$

\* A switch, $t_{2, ref}$ was introduced to the model, selecting the reference for time $t_2$. In the default position ($t_{2, ref} = 1$) the B$\rightarrow$P activation time is $t_0-t_1 + \Delta t_2$. When the switch is set to $t_{2, ref} = 0$, the activation time is $t_0 + \Delta t_2$, that is, it can only occur after the nuclear envelope breakdown. The idea of the switch was to separate pink and red curves, as observed in some data sets.

I use a Markov chain approach. The next state is generated from the current state based on rules outlined above. The rates, $k$, are converted into probabilities over a given time step $\Delta t$ as $Pr = 1 - e^{1 - k\Delta t}$. The transition time, $t_1$, is generated before the simulation starts for a given cell.

The cell timeline is repeated for $n_{\rm cell}$ times and then the colour proportions are found at each time point.

## Example

Here is an example of the model.

```{r model_example_t1, fig.width=4, fig.height=3}
pars <- c3pars(
  t0 = 0,
  tau1 = 10,
  tau2 = 10,
  k1 = 0.05,
  k2 = 0.04,
  t2ref = 1
)
chr <- ChromCom3(pars)
chr <- generateCells(chr, ncells=3000)
plotTimelines(chr, withpars=TRUE)
```

And here is an example of the the model where P$\rightarrow$R transition can occur only after $t_0 = 0$.

```{r model_example_t0, fig.width=4, fig.height=3}
pars <- c3pars(
  t0 = -10,
  tau1 = 10,
  tau2 = 10,
  k1 = 0.06,
  k2 = 0.03,
  t2re = 0
)
chr <- ChromCom3(pars)
chr <- generateCells(chr, ncells=3000)
plotTimelines(chr, withpars=TRUE)
```


## Parameter tuner

There is a [shiny app](https://shiny.compbio.dundee.ac.uk/marek_chromcom/param_tuner/) that allows tuning parameters in search for the best solution.

# Fitting model to the data

I attempted fitting model to our data. It is not an easy task, as the model is stochastic. After some testing I found that modified BFGS (a quasi-Newton method, also known as a variable metric algorithm, by Broyden, Fletcher, Goldfarb and Shanno, 1970) which allows box constraints (Byrd et al. 1995), gives reasonable results. Again, due to stochasticity of the model, this algorithm often finds false local minima. I run it several times to find the best minimum. It is a crude and time-consuming method, but gives results better than manual tuning.

Fitting is constrained to time points between -50 and 30 min. The minimized quantity is

${\rm rms} = \sqrt{\sum_{c \in \{B,P,R\}} \sum_i (O_{c,i} - E_{c,i})^2}$

that is, the square root of the sum of squared residuals over all time points and all colours.

## Default model

First, we fit the model with $\tau_1$, $\tau_2$, $k_1$ and $k_2$ free. To improve the chances of finding the correct global minimum, I run the fit with 10,000 cells and 100 tries.

### Scramble

We suspect that $t_0$ might not be exactly zero. Hence I fit the model with $t_0 = 0, -5, -10, -15$ minutes.

```{r scramble_t0, include=FALSE}
pars <- c3pars(
  t0 = -10,
  tau1 = 15.3,
  tau2 = 9,
  k1 = 0.047,
  k2 = 0.064
)
free <- c("tau1", "k1", "k2", "tau2")

neb <- c(0, -5, -10, -15)
chr.scr <- lapply(neb, function(t0) {
  name <- paste0("fitt_scramble_n10000_t.", -t0, "_tau1_k1_k2_tau2")
  cacheData(name, fitChr, echr$scramble, pars, free, ncells=10000, ntry=100, ncores=4, binDir=binDir, cacheonly=TRUE)
})
names(chr.scr) <- as.character(-neb)
```

```{r fig_scramble_t0, fig.width=5}
for(t0 in names(chr.scr)) {
  print(plotTimelines(chr.scr[[t0]], expdata = echr$scramble, withpars=TRUE))
}
```

I think the issue here is not $t_0$ but the fact that the red curve growths is too fast and the model cannot do it.

### All conditions

```{r, eval=FALSE}
# Somehow, the wrong version was used to do fitting and pars$t2ref is a string.
# Need to convert (only once).
for(set in names(dataFile)) {
  name <- paste0("fits_", set, "_ref1_t0_n100000_tau1_k1_k2_tau2")
  chr <- cacheData(name, binDir=binDir, cacheonly=TRUE)
  chr$pars$t2ref <- 1L
  file <- paste0(binDir, "/", name, ".RData")
  obj <- chr
  save(obj, file=file)
}
```

```{r plot_all_conditions_function}
plotAllConditions <- function(suffix) {
  nms <- names(dataFile)
  chr <- lapply(nms, function(set) {
    name <- paste0("fits_", set, "_", suffix)
    if(file.exists(paste0("../RData/", name, ".RData"))) {
      cacheData(name, binDir=binDir, cacheonly=TRUE)
    }
  })
  names(chr) <- nms
  P <- list()
  for(name in nms) {
    if(!is.null(chr[[name]])) {
      P[[name]] <- plotTimelines(chr[[name]], expdata = echr[[name]], withpars=TRUE, title=name, title.size=9)
    }
  }
  P
}
```


Here are fit results for all conditions with $t_0$ fixed at zero and four parameters free: $\tau_1$, $\tau_2$, $k_1$ and $k_2$.


```{r fig_all_conditions, fig.width=12, fig.height=20}
P <- plotAllConditions("ref1_t0_n10000_tau1_k1_k2_tau2")
grid.arrange(grobs=P, ncol=2)
```


## Switch: P$\rightarrow$R only after $t_0$

Here are results from a modified model, where P$\rightarrow$R transition can happen only after $t_0$. By default  $t_0 = 0$ and the results are shown in the left panels below. As you can see, the red curve in the model lags behind the red curve in the data. Hence, I fitted the data again, but fixing $t_0 = -10$ min this time (right panels). This aligns the red curves a little better.

We can also see that the pink curve is more peaked, as opposed to the smooth rise and decay in the default model.

```{r fig_all_conditions_switch, fig.width=12, fig.height=28}
P1 <- plotAllConditions("ref0_t0_n10000_tau1_k1_k2_tau2")
P2 <- plotAllConditions("ref0_t10_n10000_tau1_k1_k2_tau2")
P <- c(rbind(P1, P2))  # interleave lists (beautiful trick!)
grid.arrange(grobs=P, ncol=2)
```

# Four-colour plots

Here I create cell-line plots for all data sets using four colours.


```{r four_colour}
echr4 <- lapply(dataFile, function(file) experimentalData(file, map=model.colours.extended))
P <- lapply(names(echr4), function(nm) plotCells(echr4[[nm]], palette=c("blue", "chocolate4", "pink", "red")) + labs(title=nm))
names(P) <- names(echr4)
```

```{r fig_four_colours, fig.width=12, fig.height=28}
grid.arrange(grobs=P, ncol=2) 
```

PDF files:

```{r four_colours_pdf}
public_html <- "http://www.compbio.dundee.ac.uk/user/mgierlinski/chromcom/"
df <- NULL
for(nm in names(P)) {
  file <- paste0(nm, "_4colour.pdf")
  remote.file <- paste0("/home/mgierlinski/projects/chromcom/pdf/", file)
  url <- paste0(public_html, "pdf/", file)
  link <- paste0("[", nm, "](", url, ")")
  df <- rbind(df, data.frame(link=link))
  ggsave(remote.file, P[[nm]], device="pdf")
}
kable(df, format="html", row.names=FALSE) %>% kable_styling("condensed", full_width = FALSE, position="left", font_size=12)
```

# Brown density

```{r colour_1D_map}
colourMap <- function(echr, condition, window=c(-300,-20), colour="N") {
  ch <- echr[[condition]]
  cells <- ch$cells
  sel.win <- ch$time >= window[1] & ch$time <= window[2]
  cells <- cells[, sel.win]
  colnames(cells) <- ch$time[sel.win]
  map <- cells == colour
  cmap <- list()
  k <- 1
  for(i in 1:nrow(map)) {
    row <- map[i, ]
    # trim NAs at both ends
    good <- which(!is.na(row))
    if(length(good) > 0) {
      row <- row[min(good):max(good)]
      cmap[[k]] <- row
      k <- k + 1
    }
  }
  cmap
}

cmapDensity <- function(cmap) {
  smap <- na.omit(do.call(c, cmap))
  lambda <- sum(smap) / length(smap)
}

intervalDistribution <- function(cmap) {
  lambda <- cmapDensity(cmap)
  dist <- lapply(cmap, function(row) {
    # fill NAs
    gaps <- which(is.na(row))
    if(length(gaps) > 0) row[gaps] <- runif(length(gaps)) < lambda
    # mark intervals
    w <- which(row)
    w <- as.numeric(names(w))  # time points
    if(length(w) > 1) {
      w[2:length(w)] - w[1:(length(w)-1)]   # intervals between colours
    }
  })
  dist[sapply(dist, is.null)] <- NULL  # remove NULLs
  do.call(c, dist)
}

gapDistribution <- function(cmap) {
  lambda <- cmapDensity(cmap)
  dist <- lapply(cmap, function(row) {
    # fill NAs
    gaps <- which(is.na(row))
    if(length(gaps) > 0) row[gaps] <- runif(length(gaps)) < lambda
    # trim FALSE at ends
    good <- which(row)
    if(length(good) > 1) {
      row <- row[min(good):max(good)]
      #  gap intervals
      r <- rle(row)
      w <- r$lengths[!r$values]
      t <- as.numeric(names(row))
      time.step <- t[2] - t[1]
      w <- w * time.step
    }
  })
  dist[sapply(dist, is.null)] <- NULL  # remove NULLs
  do.call(c, dist)
}



randomMap <- function(cmap) {
  P <- cmapDensity(cmap)
  
  rmap <- lapply(cmap, function(row){
    r <- runif(length(row)) < P
    names(r) <- names(row)
    r
  })
}
```


```{r plot_interval_distribution_function}
plotIntervalDistribution <- function(echr, condition, window, with.theoretical=FALSE, what="interval") {
  cmap <- colourMap(echr, condition, window=window)
  if(what == "interval") {
    dist <- intervalDistribution(cmap)
  } else {
    dist <- gapDistribution(cmap)
  }
  
  # find density
  lambda <- cmapDensity(cmap)

  # random dist repeated 100 times to smooth
  r <- lapply(1:100, function(i){
    rmap <- randomMap(cmap)
    if(what == "interval") {
      rdist <- intervalDistribution(rmap)
    } else {
      rdist <- gapDistribution(rmap)
    }
  })
  rdist <- do.call(c, r)
  
  ks <- ks.test(dist, rdist)
  p.value <- ks$p.value

  # expected theoretical distribution
  xx <- 1:60
  yy <- lambda * exp(-lambda * xx)

  timestep <- echr[[condition]]$timepars$step
  
  df <- data.frame(dist=dist)
  rf <- data.frame(dist=rdist)
  breaks <- timestep*(seq(60) - 1.5)
  xlab <- ifelse(what == "interval", "Point-to-point duration (min)", "Gap between duration (min)")
  g <- ggplot(df, aes(dist)) +
    geom_histogram(aes(y=..density..), breaks=breaks) +
    geom_histogram(data=rf, aes(x=dist, y=..density..), breaks=breaks, colour=cbPalette[2], fill=NA) +
    xlim(0, 40) +
    labs(x=xlab, y="Density", title=paste(condition, sprintf("d=%5.3f p=%.2g", lambda, p.value)))
  if(with.theoretical) g <- g + geom_point(data=data.frame(x=xx, y=yy), aes(x, y), colour=cbPalette[1])
  g
}
```

Here I calculate the density of brown boxes and the distribution of intervals between them. If brown points are distributed randomly with density $\lambda$, the intervals between them should follow the exponential distribution with PDF

$f(d) = \lambda e^{-\lambda d}$

where $d$ is duration of the interval between consecutive brown points. Because some of the cells have much shorter data tracks, they will bias the interval distribution towards shorter intervals. The longer distances are missing from these short tracks. To account for this I made a simple model, in which I take cell tracks from the actual data, fill them randomly with brown points and calculate interval distribution. This is done 100 times to smooth the distribution.

The example below shows the result for scramble. The black bars represent data, the orange points show the predicted theoretical distribution $f(d) = \lambda e^{-\lambda d}$ and the open blue bars show the simulated random distribution. As we can see, the simulated distribution predicts more short intervals with respect to the theoretical distribution, as expected.

I use a window of [-300, -20] min.

```{r brown_distribution_example, fig.width=5, fig.height=4}
plotIntervalDistribution(echr4, "scramble", c(-300, -20), with.theoretical = TRUE, what="interval")
plotIntervalDistribution(echr4, "scramble", c(-300, -20), with.theoretical = FALSE, what="gap") 
```

## Brown-to-brown interval distributions

Below, are results for all conditions. For clarity, I don't shows theoretical points. The number in the title is the brown point density $\lambda$ (proportion of brown boxes).

```{r interval_distributions, fig.width=7, fig.height=28}
P <- list()
k <- 1
for(nm in names(echr4)) {
  P[[k]] <- plotIntervalDistribution(echr4, nm, c(-300, -20), what="interval")
  P[[k+1]] <- plotIntervalDistribution(echr4, nm, c(-300, -20), what="gap")
  k <- k + 2
}
grid.arrange(grobs=P, ncol=2)
```

## K-S tests

Now, I do K-S test between each pair of distirbutions. P-values are in the table below.

```{r brown_distribution_KS}
getDist <- function(condition, window) {
  cmap <- colourMap(echr4, condition, window=window)
  dist <- gapDistribution(cmap)
}
 
window <- c(-300, -20)
n <- length(names(echr4))
mx <- matrix(rep("-", n*n), n)
colnames(mx) <- names(echr4)
rownames(mx) <- names(echr4)
for(i in 1:(n-1)) {
  for(j in (i+1):n) {
    cond1 <- names(echr4)[i]
    cond2 <- names(echr4)[j]
    dist1 <- getDist(cond1, window)
    dist2 <- getDist(cond2, window)
    ks <- ks.test(dist1, dist2)
    p <- sprintf("%.2g", ks$p.value)
    mx[cond1, cond2] <- p
    mx[cond2, cond1] <- p
  }
}


kable(mx, format="html", row.names=TRUE) %>% kable_styling("condensed", full_width = FALSE, position="left", font_size=12)
```


## S and G2 data

```{r read_G2_S}
patDataFile <- list(
  S_phase = "../data/TT104_patterning_S_noncoloured.csv",
  G2_phase = "../data/TT104_patterning_late_G2_noncoloured.csv"
)
pchr <- lapply(patDataFile, function(file) experimentalData(file, map=model.colours.extended))
```

```{r plot_S_G2, fig.width=6, fig.height=4}
plotCells(pchr$S_phase, palette=c("blue", "chocolate4", "pink", "red"))
plotCells(pchr$G2_phase, palette=c("blue", "chocolate4", "pink", "red"))
```


```{r interval_distributions_G2_S, fig.width=7, fig.height=6}
P <- list()
k <- 1
for(nm in names(pchr)) {
  P[[k]] <- plotIntervalDistribution(pchr, nm, c(-300, 300), what="interval")
  P[[k+1]] <- plotIntervalDistribution(pchr, nm, c(-300, 300), what="gap")
  k <- k + 2
}
grid.arrange(grobs=P, ncol=2)
```
